### Problem 1
```{r}
library(modeldata)
data(biomass)
```
#(a)
```{r}
bio<-subset(biomass, select=-c(sample,dataset))
plot(bio$carbon,bio$HHV,xlab='carbon',ylab='HHV')
```

```{r}
plot(bio$hydrogen,bio$HHV,xlab='carbon',ylab='HHV')
```

```{r}
plot(bio$oxygen,bio$HHV,xlab='carbon',ylab='HHV')
```

```{r}
plot(bio$nitrogen,bio$HHV,xlab='carbon',ylab='HHV')
```

```{r}
plot(bio$sulfur,bio$HHV,xlab='carbon',ylab='HHV')
```

Comment: The most relevant predictor is carbon.

#(b)

```{r}
library(caret)
train_ind<-createDataPartition(bio$HHV,p=0.8,list=FALSE)
train <- bio[train_ind,]
test <- bio[-train_ind,]
```

#(c)
```{r}
library(leaps)
models<-regsubsets(HHV~.,data=train,nvmax=5)
```

```{r}
plot(models,scale='Cp')
```
```{r}
plot(models,scale='bic')
```
```{r}
plot(models,scale='adjr2')
```

Comment: Cp, BIC and adjusted R2 all suggest the model with carbon, hydrogen and sulfur is the best model.

#(d)
```{r}
models_f<-regsubsets(HHV~.,data=train,nvmax=5,method='forward')
```

```{r}
plot(models_f,scale='Cp')
```

```{r}
plot(models_f,scale='bic')
```

```{r}
plot(models_f,scale='adjr2')
```

```{r}
models_b<-regsubsets(HHV~.,data=train,nvmax=5,method='backward')
```

```{r}
plot(models_b,scale='Cp')
```

```{r}
plot(models_b,scale='bic')
```

```{r}
plot(models_b,scale='adjr2')
```

Comment: In the cases of backward and forward, the best models are the same.

#(e)
```{r}
errors=rep(0,5)
test_mat=model.matrix(HHV~.,data=test)
for(i in 1:5){
  coef1=coef(models,id=i)
  pred=test_mat[,names(coef1)]%*%coef1
  errors[i]=sqrt(mean((test$HHV-pred)^2))
}
errors
```
Comment: From RMSE on the testing dataset, we can see that the best model is the model with only carbon being the predictor.
Our 'best' model doesn't perform best here.

### Problem 2
```{r}
data(lending_club)
```
#(a)
```{r}
library(dplyr)
library(corrplot)
lc <- select(lending_club, -term, -sub_grade, -addr_state, -verification_status, -emp_length, -Class)
corrplot(lc %>% cor(), method = 'pie',type='upper', order='hclust')
```
#(b)
```{r}
ncol(lc)
models2=regsubsets(int_rate~.,data=lc,nvmax=16)
```

```{r}
plot(models2,scale='Cp')
```
```{r}
plot(models2,scale='bic')
```

```{r}
plot(models2,scale='adjr2')
```

```{r}
models2_f=regsubsets(int_rate~.,data=lc,nvmax=16,method='forward')
```

```{r}
plot(models2_f,scale='Cp')
```

```{r}
plot(models2_f,scale='bic')
```

```{r}
plot(models2_f,scale='adjr2')
```

```{r}
models2_b=regsubsets(int_rate~.,data=lc,nvmax=16,method='backward')
```

```{r}
plot(models2_b,scale='Cp')
```

```{r}
plot(models2_b,scale='bic')
```

```{r}
plot(models2_b,scale='adjr2')
```

Comment: The best models computed by best, forward and backward methods in the same metric are the same. The best models in different metrics of cp, bic and adjr2 are different.

#(c)
```{r}
k=5
set.seed(1)
folds=sample(1:k,nrow(lc),replace=TRUE)
errors2=matrix(NA,k,16, dimnames=list(NULL, paste(1:16)))
```

```{r}
for(j in 1:k){
  temp_models=regsubsets(int_rate~.,data=lc[folds!=j,], nvmax=16)
  test_mat = model.matrix(int_rate~., data = lc[folds==j,]) 
  for(i in 1:16){
    coefi= coef(temp_models, id = i)
    pred=test_mat[,names(coefi)]%*%coefi
    errors2[j,i]=mean((lc$int_rate[folds==j]-pred)^2)
  }
}
sort(apply(errors2,MARGIN=2,mean))
```
We can compare the best two models in the metric of Cp. The best model has the lowest MSE here. The second best model has the fourth lowest MSE here.

### Problem 3

#(a)
Actually there are $\begin{pmatrix}n\\m\end{pmatrix}$ ways to choose the training set. But actually in k-fold cross-validation training set and testing set are symmetric. We need to divided that value by 2. We got $\frac{1}{2}\begin{pmatrix}n\\m\end{pmatrix}$

#(b)
Actually there are $\begin{pmatrix}n\\m\end{pmatrix}*\begin{pmatrix}n-m\\m\end{pmatrix}=\frac{n!}{m!m!m!}$ ways to choose the three sets. The three sets are of the same status in this problem. So we got $\frac{n!}{3!m!m!m!}$

#(c)
$$\frac{n!}{k!m!m!m!}$$
When $k=n$, we got $1$. Actually in LOOCV there is only one way of partition.

### Problem 4
```{r}
library(rstudioapi)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))

adver=read.csv('Advertising.csv')
```
#(a)
```{r}
adver<-adver[,-1]
k=10
folds=sample(1:k,nrow(adver),replace=TRUE)
errors3=matrix(NA,k,4, dimnames=list(NULL, paste(1:4)))
```

```{r}
for(j in 1:k){
  model1<-lm(Sales~.,data=adver[folds!=j,])
  model2<-lm(Sales~.+TV*Radio,data=
               adver[folds!=j,])
  model3<-lm(Sales~.+TV*Newspaper,data=
               adver[folds!=j,])
  model4<-lm(Sales~.+Newspaper*Radio,data=
               adver[folds!=j,])
  
  test_mat = model.matrix(Sales~., data =
                            adver[folds==j,]) 
  
  coef1= model1$coefficients
  coef2= model2$coefficients
  coef3= model3$coefficients
  coef4= model4$coefficients
  
  pred1=test_mat[,names(coef1)]%*%coef1[1:4]
  pred2=test_mat[,names(coef1)]%*%coef2[1:4]+
    test_mat[,'TV']*test_mat[,'Radio']*coef2[5]
  pred3=test_mat[,names(coef1)]%*%coef3[1:4]+
    test_mat[,'TV']*test_mat[,'Newspaper']*
    coef3[5]
  pred4=test_mat[,names(coef1)]%*%coef4[1:4]+
    test_mat[,'Radio']*test_mat[,'Newspaper']*
    coef4[5]
  
  errors3[j,1]=mean((adver$Sales[folds==j]-pred1)^2)
  errors3[j,2]=mean((adver$Sales[folds==j]-pred2)^2)
  errors3[j,3]=mean((adver$Sales[folds==j]-pred3)^2)
  errors3[j,4]=mean((adver$Sales[folds==j]-pred4)^2)
}
sort(apply(errors3,MARGIN=2,mean))
```
Comment: Yes, and the best model includes an interaction term of TV and Radio.

#(b)
```{r}
library(ggplot2)
library(reshape2)
model5<-lm(Sales~.+TV*Radio,data=adver)
coff=model5$coefficients
coff
dol<-seq(1,100)
lin<-function(x,cof){
  return(x*cof[2]+cof[1])
}
viz_df<-data.frame(x=dol,TV=lin(dol,coff[c(1,2)]),Radio=lin(dol,coff[c(1,3)]),Newspaper=lin(dol,coff[c(1,4)]))
mdf<-melt(viz_df,id='x')

ggplot(mdf,aes(x=x,y=value,color=variable))+
  geom_line()
```


Actually when $0.019+0.001Radio>0.028+0.001TV$, it's better to increase advertising dollars of TV, otherwise increase dollars of Radio.

### Problem 5

#(a)
```{r}
x_pre=rnorm(100)
epsilon=rnorm(100)
```

#(b)
```{r}
beta=c(1,2,3,4)
y=beta[1]+beta[2]*x_pre+beta[3]*x_pre*x_pre+beta[4]*x_pre*x_pre*x_pre+epsilon
```

#(b)
```{r}
mydf<-data.frame(y=y,x=x_pre,x2=x_pre^2,x3=x_pre^3,x4=x_pre^4,x5=x_pre^5,x6=x_pre^6,x7=x_pre^7,x8=x_pre^8,x9=x_pre^9,x10=x_pre^10)
```

```{r}
models3<-regsubsets(y~.,data=mydf,nvm=10)
```

```{r}
plot(models3,scale='Cp')
```

```{r}
plot(models3,scale='bic')
```

```{r}
plot(models3,scale='adjr2')
```
Comment: According to Cp, the model with terms of x, x^2, x^3 is the best model. According to bic, the model with terms of x, x^2, x^3 is the best model. According to adjr2, the model with terms of x, x^2, x^3, x^5, x^7, x^8, x^10 is the best model.

# Cp
```{r}
coef(models3,id=3)
```
# bic
```{r}
coef(models3,id=3)
```
# adjr2
```{r}
coef(models3,id=7)
```

#(d)

# Forward
```{r}
models3_f<-regsubsets(y~.,data=mydf,nvm=10,method='forward')
```

```{r}
plot(models3_f, scale='Cp')
```

```{r}
plot(models3_f, scale='bic')
```

```{r}
plot(models3_f, scale='adjr2')
```

Comment: According to Cp, the model with terms of x, x^2, x^3 is the best model. According to bic, the model with terms of x, x^2, x^3 is the best model. According to adjr2, the model with terms of x, x^2, x^3, x^5, x^6, x^7, x^10 is the best model.

# Cp
```{r}
coef(models3,id=3)
```
# bic
```{r}
coef(models3,id=3)
```
# adjr2
```{r}
coef(models3,id=7)
```

# Backward
```{r}
models3_b<-regsubsets(y~.,data=mydf,nvm=10,method='backward')
```

```{r}
plot(models3_b, scale='Cp')
```

```{r}
plot(models3_b, scale='bic')
```

```{r}
plot(models3_b, scale='adjr2')
```

Comment: According to Cp, the model with terms of x, x^2, x^3 is the best model. According to bic, the model with terms of x, x^2, x^3 is the best model. According to adjr2, the model with terms of x, x^2, x^3, x^5, x^6, x^7, x^10 is the best model.

# Cp
```{r}
coef(models3,id=3)
```
# bic
```{r}
coef(models3,id=3)
```
# adjr2
```{r}
coef(models3,id=7)
```

Comment: The best models in terms of Cp and bic through forward and backward method are the same as what they are in full method. The best models in terms of adjr2 through forward and backward method are different from what they are in full method but with the same number of predictors.