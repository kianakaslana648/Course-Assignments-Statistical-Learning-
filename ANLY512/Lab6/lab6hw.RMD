### Problem 1
```{r}
library(ISLR)
data(Weekly)
head(Weekly)
attach(Weekly)
```

```{r}
library(gam)
fit4 <- gam(Volume~poly(Lag1,3)+poly(Lag2,3)+poly(Lag3,3))
summary(fit4)
```

```{r}
par(mfrow=c(1,3))
plot(fit4,se=TRUE)
```
```{r}
plot(Volume, col='darkgrey',type='l')
preds.Weekly=predict(fit4,se=TRUE)
lines(preds.Weekly$fit,lwd=2,col='blue')
```
```{r}
plot.ts(log10(Volume),type='l')
```
```{r}
fit.s1=smooth.spline(log10(Volume)~1:1089,df=2)
preds.s1=predict(fit.s1)
plot.ts(log10(Volume),col='darkgrey')
lines(preds.s1$y,lwd=2)
```

```{r}
fit.s1 = smooth.spline(log10(Volume) ~ 1:1089, df = 2)
preds.s1 = predict(fit.s1)
fit.s22 = smooth.spline(log10(Volume) ~ 1:1089, df = 22)
preds.s22 = predict(fit.s22)
```

```{r}
plot(log10(Volume), col = "darkgrey")
lines(preds.s1$y, lwd =2 )
lines(preds.s22$y, lwd =2, col = 2)
```

```{r}
fit.s85 = smooth.spline(log10(Volume) ~ 1:1089, df = 85)
preds.s85 = predict(fit.s85)
```

```{r}
plot(log10(Volume), col = "darkgrey")
lines(preds.s85$y, lwd =2, col = 4)
```

```{r}
fit.s = smooth.spline(log10(Volume) ~ 1:1089)
preds.s = predict(fit.s)
```

```{r}
plot(log10(Volume), col = "darkgrey")
lines(preds.s$y, lwd =2, col = 4)
```

Comment:
(1) While the first gam model doesn't work quite well for the model, after we made a log-transformation to the response, we can achieve good models by smooth splines.
(2) When the degree of the spline is larger, we have a model with higher variance and lower bias.

### Problem 2
```{r}
data(College)
head(College)
```

#(a)
```{r}
library(caret)
library(leaps)
set.seed(123)
train_set <- createDataPartition(College$Outstate,p=0.8,list=FALSE)
train<-College[train_set,]
test<-College[-train_set,]

regfit_forward<-regsubsets(Outstate~.,data=train,nvmax=17,method='forward')
plot(regfit_forward,scale='bic')
```

Comment:
The best model is the model with predictors of PrivateYes, Apps, Accept, F.Undergrad, Room.Board, Personal, PhD, Terminal, S.F.Ratio, perc.alumni, Expend, Grad.Rate.

#(b)
```{r}
model<-gam(Outstate~Private+poly(Apps,3)+poly(Accept,3)+poly(F.Undergrad,3)+poly(Room.Board,3)+poly(Personal,3)+poly(PhD,3)+poly(Terminal,3)+poly(S.F.Ratio,3)+poly(perc.alumni,3)+poly(Expend,3)+poly(Grad.Rate,3),data=train)
plot(model,se=TRUE)
```

```{r}
summary(model)
```

Comment:
All the predictors are significant. 
Findings:
(1) Predictors of Apps and Accept seem to have two parts, which indicates we could use bs or ns.
(2) If the college is private, it tends to have a larger value of Outstate.

#(c)
```{r}
mean((predict(model,test)-test$Outstate)**2)
```
The test error is so large, which indicates the model is not a good model.

#(d)
```{r}
attach(College)
plot(Apps,Outstate)
```

```{r}
plot(Accept,Outstate)
```

```{r}
plot(F.Undergrad,Outstate)
```

```{r}
plot(Room.Board,Outstate)
```

```{r}
plot(Grad.Rate,Outstate)
```

There is evidence of nonlinear relationship between Room.Board and the response.